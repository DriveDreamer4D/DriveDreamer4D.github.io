<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>DriveDreamer4D</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1296">
    <meta property="og:image:height" content="840">
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Street Gaussians for Modeling Dynamic Urban Scenes" />
    <meta property="og:description" content="     
    This paper aims to tackle the problem of modeling dynamic urban streets for autonomous driving scenes.
    Recent methods extend NeRF by incorporating tracked vehicle poses to animate vehicles, enabling photo-realistic view synthesis of dynamic urban street scenes. 
    However, significant limitations are their slow training and rendering speed.
    We introduce Street Gaussians, a new explicit scene representation that tackles these limitations. 
    Specifically, the dynamic urban scene is represented as a set of point clouds equipped with semantic logits and 3D Gaussians, each associated with either a foreground vehicle or the background. 
    To model the dynamics of foreground object vehicles, each object point cloud is optimized with optimizable tracked poses, along with a 4D spherical harmonics model for the dynamic appearance. 
    The explicit representation allows easy composition of object vehicles and background, which in turn allows for scene editing operations and rendering at 135 FPS (1066 * 1600 resolution) within half an hour of training. 
    The proposed method is evaluated on multiple challenging benchmarks, including KITTI and Waymo Open datasets. Experiments show that the proposed method consistently outperforms state-of-the-art methods across all datasets."
    />

    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Street Gaussians for Modeling Dynamic Urban Scenes" />
    <meta name="twitter:description" content="     
    This paper aims to tackle the problem of modeling dynamic urban streets for autonomous driving scenes.
    Recent methods extend NeRF by incorporating tracked vehicle poses to animate vehicles, enabling photo-realistic view synthesis of dynamic urban street scenes. 
    However, significant limitations are their slow training and rendering speed.
    We introduce Street Gaussians, a new explicit scene representation that tackles these limitations. 
    Specifically, the dynamic urban scene is represented as a set of point clouds equipped with semantic logits and 3D Gaussians, each associated with either a foreground vehicle or the background. 
    To model the dynamics of foreground object vehicles, each object point cloud is optimized with optimizable tracked poses, along with a 4D spherical harmonics model for the dynamic appearance. 
    The explicit representation allows easy composition of object vehicles and background, which in turn allows for scene editing operations and rendering at 135 FPS (1066 * 1600 resolution) within half an hour of training. 
    The proposed method is evaluated on multiple challenging benchmarks, including KITTI and Waymo Open datasets. Experiments show that the proposed method consistently outperforms state-of-the-art methods across all datasets."
    />
    <!-- <link rel="icon" href="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text y=%22.9em%22 font-size=%2290%22&gt;%E2%9C%A8&lt;/text&gt;&lt;/svg&gt;"> -->
    <!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⛐</text></svg>"> -->
    <link rel="icon" href="./img/bot-driving-car.png">

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    <script src="js/video_comparison.js"></script>
    <script src="js/app.js"></script>

    <style>
        .slick-prev:before,
        .slick-next:before {
            color: black;

        }
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
        }
        /* 设置段落文本对齐方式 */
        p {
            text-align: justify; /* 使段落文本两端对齐 */
            text-justify: inter-word; /* 改进英文对齐，增加单词间隔 */
        }
        /* .container {
            margin-left: -100px;
        } */
        .image-row {
            display: flex;
            justify-content: center;
        }

        .image-wrapper {
            margin: 0 10px;
            text-align: center;
        }

        .caption-row {
            align-items: flex-end;
        }

        .caption-row .image-wrapper {
            margin-bottom: 20px;
        }

        .caption-row .image-wrapper p {
            margin-top: 10px;
        }
    </style>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                <b>DriveDreamer4D:</b> World Models Are Effective Data Machines for 4D Driving Scene Representation </br>            
            <small>
                <!-- cvpr -->
            </small>
            </h2>

        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        Guosheng Zhao<sup>1,2</sup>
                    </li>
                    <li>
                        Chaojun Ni<sup>1,3</sup>
                    </li>
                    <li>
                        Xiaofeng Wang<sup>1,2</sup>
                    </li>
                    <li>
                        Zheng Zhu<sup>1</sup><span class="envelope">&#9993;</span>
                    </li>
                    <li>
                        Guan Huang<sup>1</sup>
                    </li>
                </ul>
                <ul class="list-inline">
                    <li>
                        Xinze Chen<sup>1</sup>
                    </li>
                    <li>
                        Boyuan Wang<sup>1,2</sup>
                    </li>
                    <li>
                        Youyi Zhang<sup>4</sup>
                    </li>
                    <li>
                        Wenjun Mei<sup>3</sup>
                    </li>
                    <li>
                        Xingang Wang<sup>2</sup><span class="envelope">&#9993;</span>
                    </li>
                </ul>
                <ul class="list-inline">
                    <li>
                        <sup>1</sup> GigaAI
                    </li>
                    <li>
                        <sup>2</sup> Institute of Automation, Chinese Academy of Sciences
                    </li>
                    <li>
                        <sup>3</sup> Peking University
                    </li>
                    <li>
                        <sup>4</sup> Technical University of Munich
                    </li>
                </ul>
            </div>
        </div>


        <div class="row">
            <div class="col-md-4 col-md-offset-4 text-center">
                <ul class="nav nav-pills nav-justified" style="margin-top:10px">
                <li>
                    <a href=https://arxiv.org/abs/2401.01339>
                    <image src="img/DriveDreamer4D-6_00.png" height="60px"></image>
                        <h4><strong>Paper</strong></h4>
                    </a>
                </li>
                <li>
                    <a href="https://github.com/GigaAI-research/DriveDreamer4D">
                    <image src="img/github.png" height="60px"></image>
                        <h4><strong>Code</strong></h4>
                    </a>
                </li>
                <!-- <li>
                    <a href="https://drive.google.com/drive/folders/1ghpE_kBwqXiWgiSWAajByjPsmj1y0l1H">
                    <image src="img/database_icon.png" height="60px"></image>
                        <h4><strong>Data</strong></h4>
                    </a>
                </li> -->
                </ul>
            </div>
        </div>

        <div class="row " style="margin-top:20px">
            <div class="col-md-8 col-md-offset-2 ">
                <img src="img/frame.png" width="100%" >
                </img>
            </div>
            <div class="col-md-8 col-md-offset-2 ">
                <p class="text-center ">
                    The pipeline of DriveDreamer4D
                </p>
            </div>
        </div>


        <div class="row ">
            <div class="col-md-8 col-md-offset-2 ">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify ">
                    <body>
                        <p>
                            Closed-loop simulation is essential for advancing end-to-end autonomous driving systems. Contemporary sensor simulation methods, such as NeRF and 3DGS, rely predominantly on conditions closely aligned with training data distributions, which are largely confined to forward-driving scenarios. Consequently, these methods face limitations when rendering complex maneuvers (e.g., lane change, acceleration, deceleration). Recent advancements in autonomous-driving world models have demonstrated the potential to generate diverse driving videos. However, these approaches remain constrained to 2D video generation, inherently lacking the spatiotemporal coherence required to capture intricacies of dynamic driving environments.
                            In this paper, we introduce <em>DriveDreamer4D</em>, which enhances 4D driving scene representation leveraging world model priors.
                            Specifically, we utilize the world model as a data machine to synthesize novel trajectory videos based on real-world driving data. Notably, we explicitly leverage structured conditions to control the spatial-temporal consistency of foreground and background elements, thus the generated data adheres closely to traffic constraints. To our knowledge, <em>DriveDreamer4D</em> is the first to utilize video generation models for improving 4D reconstruction in driving scenarios.
                            Experimental results reveal that <em>DriveDreamer4D</em> significantly enhances generation quality under novel trajectory views, achieving a relative improvement in FID by 24.5%, 39.0%, and 10.5% compared to PVG, S<sup>3</sup>Gaussian, and Deformable-GS. Moreover, <em>DriveDreamer4D</em> markedly enhances the spatiotemporal coherence of driving agents, which is verified by a comprehensive user study and the relative increases of 19.7%, 12.7%, and 11.3% in the NTA-IoU metric.
                        </p>
                    </body>
                </p>
            </div>
        </div>



        <div class="row ">
            <div class="col-md-8 col-md-offset-2 ">
                <h3>
                    Comparisons
                </h3>
                <div class="tabs">
                    <div class="tab" id='compare_video' onclick="showComparison(this)">Video</div>
                    <div class="tab active" id='compare_image' onclick="showComparison(this)">Single Frame</div>
                </div>
 
                <div class="image-row">
                    <div class="image-wrapper">
                        <div class="video-compare-container" id="seq25_compare_videoDiv" style="display: none;">
                            <video class="video" id="seq25_compare_video" loop playsinline autoPlay muted 
                                src="comparsion/005.mp4" onplay="resizeAndPlay(this)">
                            </video>
                            <canvas height=0 class="videoMerge" id="seq25_compare_videoMerge"></canvas>
                        </div>
                    </div>

                    <div class="image-wrapper">
                        <div class="video-compare-container" id="seq06_compare_videoDiv" style="display: none;">
                            <video class="video" id="seq06_compare_video" loop playsinline autoPlay muted 
                                src="comparsion/065.mp4" onplay="resizeAndPlay(this)">
                            </video>
                            <canvas height=0 class="videoMerge" id="seq06_compare_videoMerge"></canvas>
                        </div>
                    </div>
                </div>
                <div class="image-row">
                    <div class="image-wrapper">
                        <div class="video-compare-container" id="seq25_compare_imageDiv" style="display: inline;">
                            <video class="video" id="seq25_compare_image" loop playsinline autoPlay muted 
                                src="comparsion/005_combine.mp4" onplay="resizeAndPlay(this)">
                            </video>
                            <canvas height=0 class="videoMerge" id="seq25_compare_imageMerge"></canvas>
                        </div>
                    </div>

                    <div class="image-wrapper">
                        <div class="video-compare-container" id="seq06_compare_imageDiv" style="display: inline;">
                            <video class="video" id="seq06_compare_image" loop playsinline autoPlay muted 
                                src="comparsion/065_combine.mp4" onplay="resizeAndPlay(this)">
                            </video>
                            <canvas height=0 class="videoMerge" id="seq06_compare_imageMerge"></canvas>
                        </div>
                    </div>
                </div>
                <figcaption class="text-center mt-2">
                    Results of novel trajectory renderings during lane change scenarios. The left shows 
                    <span>S<sup>3</sup>Gaussian</span>, while the right shows DriveDreamer4D-<span>S<sup>3</sup>Gaussian</span>.
                </figcaption>
            </div>
        </div>
        



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3 style="display: inline-block;">
                    Rendering results in lane change novel trajectory
                </h3>
                <img src="img/turn.png" style="vertical-align: middle; margin-left: 10px;" alt="Turn icon">
                
                <div class="text-center">
                    <div style="position:relative;">
                        <div class="image-row">
                            <div class="image-wrapper">
                                <video width="100%" loop muted autoplay>
                                    <source src="comparsion/change/027_pvg.mp4" type="video/mp4" />
                                </video>
                            </div>
                        </div>

                        <div class="image-row">
                            <div class="image-wrapper">
                                <video width="100%" loop muted autoplay>
                                    <source src="comparsion/change/018_combine.mp4" type="video/mp4" />
                                </video>
                            </div>
                        </div>


                        <div class="image-row">
                            <div class="image-wrapper">
                                <video width="100%" loop muted autoplay>
                                    <source src="comparsion/change/164_df.mp4" type="video/mp4" />
                                </video>
                            </div>
                        </div>


                    </div>
                </div>
                <figcaption class="text-center mt-2">
                    Comparisons of novel trajectory renderings during lane change scenarios. The left column shows PVG, 
                    <span>S<sup>3</sup>Gaussian</span>, and Deformable-GS, while the right column shows DriveDreamer4D-PVG, 
                    DriveDreamer4D-<span>S<sup>3</sup>Gaussian</span>, and DriveDreamer4D-Deformable-GS.
                </figcaption>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Rendering results in speed change <img src="img/speed.png" style="vertical-align: middle; margin-left: 10px;" alt="Turn icon">
                </h3>
                
              
                <div class="text-center">
                    <div style="position:relative;">
                        <div class="image-row">
                            <div class="image-wrapper">
                                <video width="100%" loop muted autoplay>
                                    <source src="comparsion/acc/065_pvg.mp4" type="video/mp4" />
                                </video>
                            </div>
                        </div>

                        <div class="image-row">
                            <div class="image-wrapper">
                                <video width="100%" loop muted autoplay>
                                    <source src="comparsion/acc/121_s3.mp4" type="video/mp4" />
                                </video>
                            </div>
                        </div>
                        <div class="image-row">
                            <div class="image-wrapper">
                                <video width="100%" loop muted autoplay>
                                    <source src="comparsion/acc/096_df.mp4" type="video/mp4" />
                                </video>
                            </div>
                        </div>
                    </div>
                </div>
                <figcaption class="text-center mt-2">
                    Comparisons of novel trajectory renderings during speed change scenarios. The left column shows PVG, 
                    <span>S<sup>3</sup>Gaussian</span>, and Deformable-GS, while the right column shows DriveDreamer4D-PVG, 
                    DriveDreamer4D-<span>S<sup>3</sup>Gaussian</span>, and DriveDreamer4D-Deformable-GS.
                </figcaption>
            </div>
        </div>

        <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <textarea id="bibtex" class="form-control" readonly>
@inproceedings{yan2024street,
    title={Street Gaussians for Modeling Dynamic Urban Scenes}, 
    author={Yunzhi Yan and Haotong Lin and Chenxu Zhou and Weijie Wang and Haiyang Sun and Kun Zhan and Xianpeng Lang and Xiaowei Zhou and Sida Peng},
    booktitle={ECCV},
    year={2024},
}</textarea>
                </div>
            </div>
        </div> -->

<!-- 
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <!-- <h3>
                    Acknowledgements
                </h3> 
                <p class="text-justify">
                    The website template was borrowed from <a href="http://mgharbi.com/">Michaël Gharbi</a> and <a href="https://jonbarron.info/mipnerf360/">Jon Barron</a>.
                </p>
            </div>
        </div> -->
    </div>
</body>


</html>
